{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Synthetic Data Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from data_utils.generate_synthetic_data import make_point_clouds\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from data_utils.vectorisation_methods import get_persistence_landscapes, get_betti_curves, get_persistence_images\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we cluster the vector representations of the persistence diagrams of synthetic data for varying levels of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters for clustering with varying noise\n",
    "noise = [0, 1, 2, 3, 4, 5, 10]\n",
    "n_samples_per_class = 10\n",
    "homology_dimensions = [0, 1, 2]\n",
    "n_clusters = 3\n",
    "\n",
    "landscape_rand = [None] * len(noise)\n",
    "betti_rand = [None] * len(noise)\n",
    "image_rand = [None] * len(noise)\n",
    "\n",
    "km = KMeans(n_clusters=3, init='k-means++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PL score  PI score  BC_score\n",
      "noise                              \n",
      "0      1.000000  1.000000  1.000000\n",
      "1      1.000000  0.898170  0.274136\n",
      "2      1.000000  1.000000  0.137032\n",
      "3      1.000000  1.000000  0.077368\n",
      "4      0.898170  0.898170  0.109962\n",
      "5      0.898170  0.698192  0.109039\n",
      "10     0.500717  0.440262  0.126139\n"
     ]
    }
   ],
   "source": [
    "# calculate adjusted rand scores for clustering of data with varying noise\n",
    "for i, n in enumerate(noise):\n",
    "    # Create synthetic data of 10 samples of 4 classes, circles, spheres, tori and random point clouds\n",
    "    point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=n)\n",
    "    # Compute persistence diagrams\n",
    "    VR = VietorisRipsPersistence(homology_dimensions=homology_dimensions)\n",
    "    diagrams = VR.fit_transform(point_clouds)\n",
    "    # Compute persistence landscapes\n",
    "    p_landscapes = get_persistence_landscapes(point_clouds, diagrams, n_layers=2, n_bins=50)\n",
    "    # Compute betti curves\n",
    "    betti_curves = get_betti_curves(point_clouds, diagrams, n_bins=100)\n",
    "    # Compute persistence images\n",
    "    p_images = get_persistence_images(point_clouds, diagrams, n_bins=10)\n",
    "    # predict labels\n",
    "    landscape_preds = km.fit_predict(p_landscapes)\n",
    "    betti_preds = km.fit_predict(betti_curves)\n",
    "    image_preds = km.fit_predict(p_images)\n",
    "    # Compute rand score for each clustering\n",
    "    landscape_rand[i] = adjusted_rand_score(labels, landscape_preds)\n",
    "    betti_rand[i] = adjusted_rand_score(labels, betti_preds)\n",
    "    image_rand[i] = adjusted_rand_score(labels, image_preds)\n",
    "\n",
    "# print ARI scores in table\n",
    "vector_scores = pd.DataFrame({'noise': noise,\n",
    "                              'PL score': landscape_rand,\n",
    "                              'PI score': image_rand,\n",
    "                              'BC_score': betti_rand}).set_index('noise')\n",
    "print(vector_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We compare the clustering output of persistence landscapes and persistence images by repeating the experiment on variations of the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def persistence_comparison(homology_dimensions: list, noise: int, iters: int):\n",
    "    comparison = []\n",
    "    landscape_scores = []\n",
    "    image_scores = []\n",
    "    # calculate\n",
    "    for _ in range(iters):\n",
    "        # initialise Persistent Homology\n",
    "        VR = VietorisRipsPersistence(homology_dimensions=homology_dimensions)\n",
    "        # generate data with set noise level\n",
    "        point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=noise)\n",
    "        # create persistence diagrams\n",
    "        diagrams = VR.fit_transform(point_clouds)\n",
    "        # create persistence landscape and image vectors\n",
    "        p_landscapes = get_persistence_landscapes(point_clouds=point_clouds,\n",
    "                                                  persistence_diagrams=diagrams,\n",
    "                                                  n_layers=2,\n",
    "                                                  n_bins=50)\n",
    "        p_images = get_persistence_images(point_clouds=point_clouds,\n",
    "                                          persistence_diagrams=diagrams,\n",
    "                                          n_bins=10)\n",
    "        # cluster based on vectors\n",
    "        landscape_preds =  km.fit_predict(p_landscapes)\n",
    "        image_preds = km.fit_predict(p_images)\n",
    "        # calculate adjusted rand score for each vectorization\n",
    "        landscape_score = adjusted_rand_score(labels, landscape_preds)\n",
    "        image_score = adjusted_rand_score(labels, image_preds)\n",
    "        # append scores to list\n",
    "        landscape_scores.append(landscape_score)\n",
    "        image_scores.append(image_score)\n",
    "        # append 1 if PLs outperform PIs\n",
    "        if image_score < landscape_score:\n",
    "            comparison.append(1)\n",
    "        else:\n",
    "            comparison.append(0)\n",
    "    print(f\"For noise = {noise}, persistence landscapes outperform persistence images \"\n",
    "          f\"{round(mean(comparison) * 100, 2)}% of the time.\")\n",
    "    print(f\" Average Adjusted Rand Score for Persistence Landscapes: {round(mean(landscape_scores), 3)}\")\n",
    "    print(f\" Std. Adjusted Rand Score for Persistence Landscapes: {round(np.std(landscape_scores), 3)}\")\n",
    "    print(f\" Average Adjusted Rand Score for Persistence Images: {round(mean(image_scores), 3)}\")\n",
    "    print(f\" Std. Adjusted Rand Score for Persistence Images: {round(np.std(image_scores), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For noise = 1.0, persistence landscapes outperform persistence images 56.0% of the time.\n",
      " Average Adjusted Rand Score for Persistence Landscapes: 0.993\n",
      " Std. Adjusted Rand Score for Persistence Landscapes: 0.026\n",
      " Average Adjusted Rand Score for Persistence Images: 0.91\n",
      " Std. Adjusted Rand Score for Persistence Images: 0.094\n"
     ]
    }
   ],
   "source": [
    "# example of persistence landscape/vector comparison for noise = 1.0\n",
    "\n",
    "persistence_comparison(homology_dimensions=[0, 1, 2], noise=1.0, iters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Persistence Diagram Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this section we demonstrate running the PD and PM K-means clustering algorithms on simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from pd_pm_kmeans import PD_KMeans, PM_KMeans\n",
    "from data_utils.pd_pm_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create simulated data\n",
    "point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=1.0)\n",
    "\n",
    "# Create PDs from simulated data\n",
    "diagrams = []\n",
    "\n",
    "for pc in point_clouds:\n",
    "    norm_pc = normalise_pc(pc)\n",
    "    diag = get_pd(norm_pc)\n",
    "    diagrams.append(diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD ARI score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Clustering in Persistence Diagram Space\n",
    "km = PD_KMeans(n_clusters=3, init='kmeans++', random_state=123)\n",
    "pd_preds = km.fit(diagrams)\n",
    "print(f'PD ARI score: {adjusted_rand_score(labels, pd_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Persistence Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM ARI Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# get appropriate grid_width from list of PDs\n",
    "grid_width = get_grid_width(diagrams)\n",
    "\n",
    "# create list of PMs from PDs\n",
    "mesrs = []\n",
    "for diag in diagrams:\n",
    "    concat_diag = np.concatenate(diag)\n",
    "    mesr, _ = diag_to_mesr(concat_diag, unit_mass=1, grid_width=grid_width)\n",
    "    mesrs.append(mesr)\n",
    "\n",
    "pm_km = PM_KMeans(n_clusters=3, init='kmeans++', grid_width=grid_width)\n",
    "pm_preds = pm_km.fit(mesrs)\n",
    "\n",
    "print(f'PM ARI Score: {adjusted_rand_score(labels, pm_preds)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscenv",
   "language": "python",
   "name": "mscenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}